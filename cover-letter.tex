\documentclass[14pt]{letter}
\usepackage{graphicx}% http://ctan.org/pkg/graphicx
\setlength{\parindent}{0pt}% Remove paragraph indent
\usepackage{url}

\begin{document}
\thispagestyle{empty}

%\hspace*{0.55\linewidth}
%\begin{minipage}{0.45\linewidth}
%Dmitry I. Ignatov \par
%Faculty of Computer Science \par
%National Research University Higher School of Economics, Moscow
%\end{minipage}\par \bigskip
%
% \includegraphics[scale=0.55]{logo_hse_cmyk_e.eps}

\vspace{1.5cm}

\begin{minipage}{0.5\linewidth}
To whom it may concern, \par
\end{minipage} \par\bigskip

My name is Ivan Nazarov. I am {36} years old and have working experience since 2009.
I have been studying and working in machine learning since 2014. During this time I
have tackled industrial and applied projects, and contributed to theoretical studies,
e.g. time series forecasting, data-driven optimization in operations research, radio
frequency signal processing, decentralized optimization for anomaly detection, sparse
matrix decompositions, generating steganographic containers with GANs, variational
Bayes and sparsification methods for deep learning.
\par\medskip

In 2016 I graduated from the MSc programme on computer science at the National Research
University Higher School of Economics and in 2020 I successfully completed my PhD studies
on applied mathematics, computer science and engineering at Skoltech. The thesis is on
the topic of model sparsification: sparse-regularized matrix decompositions, variational
dropout, and parameter pruning methods based on second-order loss approximation. I have
a paper about variational Dropout for complex-valued deep networks at ICML2020%
\footnote{
    \url{https://proceedings.mlr.press/v119/nazarov20a.html}
} and co-authored several other publications in other venues.%
\footnote{
    % cannot update my email due to trade controls :(
    \url{https://scholar.google.ru/citations?user=lF5HI3QAAAAJ}
}
\par\medskip

I have advanced knowledge of python%
\footnote{
    \url{https://github.com/ivannz}
}
and have hands-on experience with developing extensions in C/Cython.
%
I recognize the value of carefully prepared numerical experiments in evaluating research
hypotheses, and the merit of place the results within a bigger picture. I know how to
plan and carry out ablation studies, and clearly communicate and visualize the findings.
%
When studying and doing research I prefer to take a broad integral look at the methods,
track their interactions, figure out influences and relations to adjacent machine learning
subfields.
%
I have no problem with engaging with complex concepts in probability and statistics,
optimization and numerical methods, differential geometry and linear algebra.
%
I feel secure in my ability to distill and combine key ideas from diverse research fields,
and enjoy communicating ideas to others through papers, presentations and teaching.
\par\medskip

In the last two years I have been consumed by the exciting and challenging field of Reinforcement
Learning and Optimal Control, specifically hierarchical policies, planning, MCTS and adaptive
computations, and our team took first place in the recent NeurIPS Nethack Challenge for
our neural-algorithmic hybrid policy (Team RAPH). More recently I was captivated by the
prospect of marrying classic search algorithms with the latest advances in machine and deep
learning and the problem of generalizing from small problems to large ones. In particular,
improving the runtime speed by practical methods to learn heuristics for Branch and Bound
solvers from a collection of small Mixed Integer Program instances with further fine-tuning
on a handful of practically relevant problems within the same class.

I intend to continue pursing research in Machine Learning and RL and I am confident that my
software engineering skills, understanding of modern DEVops practices, and diligent and broad
approach to research, coupled with excitement with AI in general, would allow me to make
meaningful contributions both the field itself and its applications.
\par\medskip

% Currently, I am particularly interested in reinforcement learning (RL) and optimal control. I am researching two directions: the problem of sub-policy discovery in hierarchical reinforcement learning, and intrinsic motivation mechanisms for meaningful exploration in procedurally generated environments. I am also pondering the idea of fusing adaptive computation approaches with the policy improvement via Monte Carlo Tree Search (MuZero + PonderNet). At the same time the following topics are also interesting to me due to my past experience: deep network sparsification and pruning, optimisation on matrix manifolds, Variational Bayes, Bayesian neural networks and Gaussian processes, active learning, statistical learning, kernel methods.

% Currently, I my research is focused on applications of machine learning to combinatorial optimization, however, due to my prior experience, I am also interested in following topics: hierarchical policies and efficient representations in reinforcement learning, model sparsification and pruning, Variational Bayes, and optimisation on matrix manifolds.

\hfill Thank you for your consideration,\par%
\hfill Ivan Nazarov

\end{document}
